{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSI_Path = \"\"\n",
    "Pos_Path = \"\"\n",
    "SNR_Path = \"\"\n",
    "#File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(CSI_Path , \"r\")\n",
    "H = f['h_Estimated'][:].T\n",
    "f.close()\n",
    "f = h5py.File(Pos_Path , \"r\")\n",
    "pos = f[\"r_Position\"][:].T\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(H, pos, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading pretrained models of PCA and CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = load(open(\"PCA_Unsupervised.sav\" , \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "best = load_model(\"Best_PCA_CNN.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating position using PCA and CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.sqrt(H[:,:,:,0]**2 + H[:,:,:,1]**2)\n",
    "temp = temp.reshape(-1,924)\n",
    "temp = pca.transform(temp)\n",
    "temp = temp.reshape(-1 , 16,66)\n",
    "temp = temp.reshape(temp.shape[0],-1,1)\n",
    "pos_cnn = best.predict(temp)\n",
    "del temp\n",
    "print(pos_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cnn_train , pos_cnn_test = train_test_split(pos_cnn, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning the estimation using TRRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TRRS:\n",
    "    ''' TRRS Class'''\n",
    "    def __init__(self, CFR , CFR_Pos):\n",
    "        self.CFR = CFR\n",
    "        self.CFR_Pos = CFR_Pos\n",
    "\n",
    "  \n",
    "    def get_fingerprint_subset(self , pos ,k=-1,radius = 1 ):\n",
    "        ''' Generates a subset of fingerprint set of points which lie in a circle of specified radius \n",
    "            around the position'''\n",
    "        out = []\n",
    "        for i in range(len(self.CFR_Pos)):\n",
    "            if i==k:\n",
    "                continue\n",
    "            if np.sqrt(np.sum((pos-self.CFR_Pos[i])**2)) < radius:\n",
    "                out.append(i)\n",
    "        return np.array(out)\n",
    "\n",
    "    def predict(self , H2 ,k, Pos2=[] , radius=1):\n",
    "        ''' Obtains subset of fingerprint if estimated position is specified or gets the complete fingerprint \n",
    "            set otherwise. Estimates position by applying Time Reversal Resonating Strength algorithm\n",
    "            using the obtained fingerprint set.'''\n",
    "        if len(Pos2)==0:\n",
    "            idx = range(len(self.CFR))\n",
    "        else:\n",
    "            idx = self.get_fingerprint_subset(Pos2 , k,radius)\n",
    "        H1 = self.CFR[idx]\n",
    "        pos = self.CFR_Pos[idx]\n",
    "        Yd1 = np.sum((H1*H1)[:,:,:,0] + (H1*H1)[:,:,:,1] , axis=2)\n",
    "        Yd2 = np.sum((H2*H2)[:,:,0] + (H2*H2)[:,:,1] , axis=1)\n",
    "        #print((Yd1*Yd2).shape)\n",
    "\n",
    "        H11 = H1[:,:,:,0] + H1[:,:,:,1] * 1j\n",
    "        H22 = H2[:,:,0] - H2[:,:,1] * 1j\n",
    "        G = H11 * H22\n",
    "        #print(G.shape)\n",
    "        Nser = 1024\n",
    "        Nu = 924\n",
    "        G = np.concatenate((G, np.zeros((H1.shape[0],16,Nser-Nu))), axis=2)\n",
    "          #print(G.shape)\n",
    "\n",
    "        g = np.fft.fftn(G, axes=(2,))\n",
    "          #print(g.shape)\n",
    "\n",
    "        phi_d = np.ndarray.max((np.square(np.abs(g))), axis=2)\n",
    "        phi_d = np.divide(phi_d,(Yd1*Yd2))\n",
    "        #print(phi_d.shape)\n",
    "\n",
    "        w_d = np.sqrt((Yd1 * Yd2))\n",
    "        w_d = np.transpose(w_d)/(np.sqrt(np.sum(Yd1, axis=1)) * np.sum(Yd2))\n",
    "        w_d = np.transpose(w_d)\n",
    "        #print(w_d.shape)\n",
    "\n",
    "        TRRS = np.sum(np.multiply(w_d,np.sqrt(phi_d)), axis=1)\n",
    "        TRRS = np.square(TRRS)\n",
    "\n",
    "        idx = np.argmax(TRRS)\n",
    "\n",
    "        return pos[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trrs = TRRS(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing import Pool\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y1,y2):\n",
    "    return np.sqrt(np.sum((y1-y2)**2 , axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_trrs_train = np.zeros(pos_cnn_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trrs(i):\n",
    "    temp = []\n",
    "    temp.append(trrs.predict(X_train[i] ,i ,pos_cnn_train[i] , radius = 0.30))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation of TRRS.\n",
    "Used multiproccesing for faster performance on multicore systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(os.cpu_count())\n",
    "for j in range(0 , len(X_train) , 100):\n",
    "    s = time.time()\n",
    "    a = range(j,min(j+100,len(X_train)))\n",
    "    pos_trrs_train[a] = np.array(pool.map(process_trrs, a))[:,0,:]\n",
    "    print(j+100)\n",
    "    end = time.time()\n",
    "    print(end-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_trrs_test = np.zeros(pos_cnn_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trrs(i):\n",
    "    temp = []\n",
    "    temp.append(trrs.predict(X_test[i] ,i ,pos_cnn_test[i] , radius = 0.30))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation of TRRS on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(os.cpu_count())\n",
    "for j in range(0 , len(X_test) , 100):\n",
    "    s = time.time()\n",
    "    a = range(j,min(j+100,len(X_test)))\n",
    "    pos_trrs_test[a] = np.array(pool.map(process_trrs, a))[:,0,:]\n",
    "    print(j+100)\n",
    "    end = time.time()\n",
    "    print(end-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.sqrt(np.sum((pos_trrs_test-y_test)**2 , axis=1))\n",
    "print(np.mean(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Root Mean Squared Error\")\n",
    "plt.hist(error,50)\n",
    "plt.savefig(\"TRRS.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading SNR data for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(SNR_Path , \"r\")\n",
    "SNR = f['SNR_Est'][:].T\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_Train , SNR_Test = train_test_split(SNR, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ensembling\n",
    "Combining SNR, Position from PCA&CNN and Position from TRRS and finetuning \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adadelta, Adam, RMSprop, SGD\n",
    "from tensorflow.keras.layers import concatenate,Dense , Add, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "def ensemble():\n",
    "    '''Simple fully connected network with residual layers'''\n",
    "    inputA = Input(shape=(16,)) #SNR\n",
    "    inputB = Input(shape=(3,)) #Estimated position from PCA and CNN\n",
    "    inputC = Input(shape=(3,)) #Estimated position from TRRS\n",
    "    comb = concatenate([inputA,inputB,inputC])\n",
    "    x = Dropout(0.05)(comb)\n",
    "    x = Dense(15, kernel_initializer='glorot_uniform')(x)\n",
    "    x = Dense(7, kernel_initializer='glorot_uniform')(x)\n",
    "    out = Dense(3)(x)\n",
    "    out = Add()([out,inputB])\n",
    "    out = Dense(3)(out)\n",
    "    out = Add()([out,inputC])\n",
    "    out = Dense(3)(out)\n",
    "    return Model(inputs=[ inputA , inputB,inputC], outputs=out)\n",
    "\n",
    "pre_final = ensemble()\n",
    "print(pre_final.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "pre_final.compile(optimizer = 'Adam', loss='mean_squared_error')\n",
    "earlystopper = EarlyStopping(patience = 20, verbose=1)\n",
    "checkpointer = ModelCheckpoint('Ensemble.h5', verbose=1, save_best_only=True)\n",
    "pre_final.fit([SNR_Train,pos_cnn_test,pos_trrs_test], y_train, epochs = 300, verbose=1, batch_size = 40, validation_split=0.3, callbacks = [checkpointer, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "ensemble = load_model(\"Ensemble.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = ensemble.predict([SNR_Test,pos_cnn_test,pos_trrs_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.sqrt(np.sum((final- y_test)**2,axis=1))\n",
    "print(np.mean(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Root Mean Squared Error\")\n",
    "plt.hist(error,50)\n",
    "plt.savefig(\"Ensemble.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
